"""
QUICK START GUIDE - AQI Analysis Project
Run this to get started immediately
"""

import os
import sys
from pathlib import Path

def print_header():
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                           â•‘
â•‘          ğŸŒ AQI ANALYSIS PROJECT - TAMIL NADU (2020-2025) ğŸŒ           â•‘
â•‘                    Quick Start Guide & Instructions                       â•‘
â•‘                                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

def print_installation_steps():
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  STEP 1: INSTALLATION & SETUP                                           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
""")
    print("\n1ï¸âƒ£  Navigate to project directory:")
    print("   cd GroceryStoreDataset")

    print("\n2ï¸âƒ£  Create Python virtual environment:")
    print("   python -m venv venv")

    print("\n3ï¸âƒ£  Activate virtual environment:")
    print("   # Windows:")
    print("   venv\\Scripts\\activate")
    print("   # Linux/Mac:")
    print("   source venv/bin/activate")

    print("\n4ï¸âƒ£  Install dependencies:")
    print("   pip install -r requirements.txt")

    print("\n" + "="*75 + "\n")

def print_pipeline_steps():
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  STEP 2: RUN DATA COLLECTION & PROCESSING PIPELINE                       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£

Option A: RUN COMPLETE PIPELINE (Recommended)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

python setup.py

This will automatically:
  âœ“ Load AQI data from CPCB
  âœ“ Clean and preprocess data
  âœ“ Engineer advanced features
  âœ“ Train ML models
  âœ“ Generate 12+ visualizations

Then it will prompt you to launch Jupyter or Dashboard.


Option B: RUN INDIVIDUAL STEPS MANUALLY
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

python src/data_loader.py           # Load data
python src/data_preprocessing.py    # Clean & preprocess
python src/features.py              # Engineer features
python src/models.py                # Train ML models
python src/visualization.py         # Create charts

""")
    print("="*75 + "\n")

def print_dashboard_steps():
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  STEP 3: LAUNCH INTERACTIVE DASHBOARD                                    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£

streamlit run dashboard/app.py

Dashboard features:
  ğŸ“Š Overview: Key metrics and latest AQI readings
  ğŸ“ˆ Charts: Interactive visualizations (12+ charts)
  ğŸ—ºï¸  Map: Geographic visualization of Tamil Nadu
  ğŸ¤– ML: Machine learning predictions and insights
  ğŸ“‹ About: Project information and metrics

The dashboard will open at: http://localhost:8501

""")
    print("="*75 + "\n")

def print_notebook_steps():
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  STEP 4: DETAILED ANALYSIS - JUPYTER NOTEBOOK                            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£

jupyter notebook notebooks/AQI_Analysis.ipynb

The notebook includes:
  1. Data Loading & Overview
  2. Exploratory Data Analysis (5+ visualizations)
  3. Statistical Analysis
  4. Machine Learning Models
  5. Results & Insights
  6. Recommendations

Run all cells (Kernel â†’ Run All) for complete analysis.

""")
    print("="*75 + "\n")

def print_project_structure():
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  PROJECT STRUCTURE & FILES                                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£

GroceryStoreDataset/
â”œâ”€â”€ ğŸ“‚ aqi_data/
â”‚   â”œâ”€â”€ raw_data/              â† Raw CSV files from API
â”‚   â”œâ”€â”€ processed_data/        â† Cleaned data & features
â”‚   â””â”€â”€ models/                â† Trained ML models
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/
â”‚   â”œâ”€â”€ AQI_Analysis.ipynb     â† Main analysis (10+ visualizations)
â”‚   â””â”€â”€ data_exploration.ipynb â† EDA notebook
â”‚
â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”œâ”€â”€ data_loader.py         â† CPCB API data fetching
â”‚   â”œâ”€â”€ data_preprocessing.py  â† Data cleaning
â”‚   â”œâ”€â”€ features.py            â† Feature engineering
â”‚   â”œâ”€â”€ models.py              â† ML models (ARIMA, LSTM, etc)
â”‚   â””â”€â”€ visualization.py       â† Chart generation (12 charts)
â”‚
â”œâ”€â”€ ğŸ“‚ dashboard/
â”‚   â”œâ”€â”€ app.py                 â† Main Streamlit app
â”‚   â””â”€â”€ assets/                â† Generated charts & maps
â”‚
â”œâ”€â”€ requirements.txt           â† Python dependencies
â”œâ”€â”€ setup.py                   â† Automated pipeline script
â”œâ”€â”€ README.md                  â† Full documentation
â””â”€â”€ QUICKSTART.md              â† This file

""")
    print("="*75 + "\n")

def print_features_summary():
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  PROJECT FEATURES & CAPABILITIES                                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£

ğŸ“Š DATA:
  â€¢ 6+ years of AQI data (2020-2025)
  â€¢ 10+ Tamil Nadu monitoring stations
  â€¢ 6 pollutants tracked: AQI, PM2.5, PM10, NOâ‚‚, SOâ‚‚, CO
  â€¢ 50,000+ data points

ğŸ”„ PROCESSING:
  â€¢ Data validation & cleaning
  â€¢ Missing value imputation
  â€¢ Outlier detection & capping
  â€¢ Temporal feature extraction
  â€¢ Statistical feature engineering
  â€¢ Standardization & normalization

ğŸ¤– MACHINE LEARNING (4 Model Types):
  1. Time Series Forecasting
     â€¢ ARIMA for trend analysis
     â€¢ LSTM for pattern prediction
  2. Classification
     â€¢ Random Forest for AQI level prediction
  3. Clustering
     â€¢ K-Means for pattern identification
     â€¢ DBSCAN for anomaly detection
  4. Anomaly Detection
     â€¢ Isolation Forest
     â€¢ Z-Score method

ğŸ“ˆ VISUALIZATIONS (12+ Charts):
  1. AQI Trend by Year
  2. AQI by Month
  3. Seasonal Patterns
  4. AQI by Station
  5. Station Performance Heatmap
  6. Top Polluted Stations
  7. AQI Distribution
  8. Pollutant Distribution
  9. Correlation Heatmap
  10. Moving Averages
  11. Year-on-Year Comparison
  12. Anomaly Detection

ğŸŒ DASHBOARD:
  â€¢ 5 interactive pages
  â€¢ Real-time filtering
  â€¢ Geographic mapping
  â€¢ ML predictions
  â€¢ Responsive design

ğŸ““ JUPYTER NOTEBOOK:
  â€¢ 10+ visualizations
  â€¢ Detailed explanations
  â€¢ Statistical analysis
  â€¢ ML model training
  â€¢ Actionable insights

""")
    print("="*75 + "\n")

def print_troubleshooting():
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  TROUBLESHOOTING & COMMON ISSUES                                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£

âŒ "ModuleNotFoundError: No module named 'streamlit'"
   â†’ Solution: pip install -r requirements.txt

âŒ "Port 8501 is already in use"
   â†’ Solution: streamlit run dashboard/app.py --server.port 8502

âŒ "No such file or directory: aqi_data/processed_data..."
   â†’ Solution: Run data_loader.py first, then data_preprocessing.py

âŒ "TensorFlow/LSTM errors"
   â†’ Solution: These are optional. Models gracefully degrade if unavailable

âŒ Memory issues with large datasets
   â†’ Solution: Process data in batches or use --profile-memory flag

ğŸ“– For more help, see README.md or check the Jupyter notebook

""")
    print("="*75 + "\n")

def print_tips():
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  TIPS & BEST PRACTICES                                                   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£

ğŸ’¡ Tips:
  â€¢ Start with Dashboard for quick insights
  â€¢ Use Jupyter for detailed analysis
  â€¢ Check data in aqi_data/processed_data/ folder
  â€¢ ML models are optional - dashboard works without them
  â€¢ Use filters in dashboard to focus on specific areas/dates

âš¡ Performance:
  â€¢ First run may take 5-10 minutes (data processing)
  â€¢ Subsequent runs are faster (cached data)
  â€¢ Dashboard loads in seconds once data is ready
  â€¢ LSTM training is CPU/GPU intensive

ğŸ“š Learning Resources:
  â€¢ README.md: Full documentation
  â€¢ AQI_Analysis.ipynb: Detailed analysis walkthrough
  â€¢ Source code comments: Implementation details

ğŸ”„ Data Updates:
  â€¢ To refresh data: Delete aqi_data/raw_data/ files
  â€¢ Then run: python src/data_loader.py

""")
    print("="*75 + "\n")

def print_next_steps():
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  NEXT STEPS                                                              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£

ğŸ¯ IMMEDIATE (Next 5 minutes):
  1. Install dependencies: pip install -r requirements.txt
  2. Run pipeline: python setup.py
  3. Launch dashboard: streamlit run dashboard/app.py

ğŸ“Š SHORT TERM (Next hour):
  1. Explore dashboard pages
  2. Check different time periods
  3. Review generated charts
  4. Open Jupyter notebook for deep dive

ğŸ”¬ LONG TERM (Next day+):
  1. Analyze trends for your specific area
  2. Train custom models with your parameters
  3. Share findings with stakeholders
  4. Use insights for decision-making

â“ Questions?
  â€¢ Check README.md for detailed documentation
  â€¢ Review Jupyter notebook for examples
  â€¢ Check source code comments
  â€¢ See GitHub issues/discussions

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                           â•‘
â•‘                    ğŸš€ READY TO GET STARTED? ğŸš€                          â•‘
â•‘                                                                           â•‘
â•‘              Run: python setup.py                                         â•‘
â•‘              Or: streamlit run dashboard/app.py                           â•‘
â•‘              Or: jupyter notebook notebooks/AQI_Analysis.ipynb           â•‘
â•‘                                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

def main():
    print_header()
    input("Press Enter to continue...")

    print_installation_steps()
    input("Press Enter to continue...")

    print_pipeline_steps()
    input("Press Enter to continue...")

    print_dashboard_steps()
    input("Press Enter to continue...")

    print_notebook_steps()
    input("Press Enter to continue...")

    print_project_structure()
    input("Press Enter to continue...")

    print_features_summary()
    input("Press Enter to continue...")

    print_troubleshooting()
    input("Press Enter to continue...")

    print_tips()
    input("Press Enter to continue...")

    print_next_steps()

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nGuide closed. Happy analyzing! ğŸŒğŸ“Š")
